---
phase: 04-production-readiness
plan: 02
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - mcps/knowledge-mcp/src/knowledge_mcp/embed/cache.py
  - mcps/knowledge-mcp/tests/unit/test_embed_cache.py
autonomous: true

must_haves:
  truths:
    - "Embedding cache stores and retrieves embeddings by content hash"
    - "Cache automatically invalidates when embedding model changes"
    - "Identical text returns cached embedding (no API call needed)"
    - "Cache statistics available for monitoring"
  artifacts:
    - path: "mcps/knowledge-mcp/src/knowledge_mcp/embed/cache.py"
      provides: "EmbeddingCache class with diskcache backend"
      exports: ["EmbeddingCache"]
      min_lines: 60
    - path: "mcps/knowledge-mcp/tests/unit/test_embed_cache.py"
      provides: "Unit tests for embedding cache"
      min_lines: 50
  key_links:
    - from: "src/knowledge_mcp/embed/cache.py"
      to: "diskcache.Cache"
      via: "import and instantiation"
      pattern: "from diskcache import Cache"
    - from: "src/knowledge_mcp/embed/cache.py"
      to: "hashlib.sha256"
      via: "content hashing"
      pattern: "sha256.*encode"
---

<objective>
Implement persistent embedding cache with content hashing to prevent duplicate embedding API calls.

Purpose: NFR-5.2 requires caching embeddings by content hash. This reduces OpenAI API costs by avoiding re-embedding unchanged content.
Output: EmbeddingCache class with get/set operations, SHA-256 content hashing, model-versioned cache paths, and comprehensive unit tests.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@mcps/knowledge-mcp/src/knowledge_mcp/embed/__init__.py
@mcps/knowledge-mcp/src/knowledge_mcp/utils/config.py
@.planning/phases/04-production-readiness/04-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement EmbeddingCache class</name>
  <files>mcps/knowledge-mcp/src/knowledge_mcp/embed/cache.py</files>
  <action>
Create `src/knowledge_mcp/embed/cache.py` implementing persistent embedding cache:

```python
"""Embedding cache with content hashing."""

from __future__ import annotations

import hashlib
from pathlib import Path
from typing import TYPE_CHECKING

from diskcache import Cache

if TYPE_CHECKING:
    pass


class EmbeddingCache:
    """
    Persistent embedding cache using content hashing.

    Cache key: SHA-256 hash of normalized text content.
    Cache invalidation: Only on embedding model change (model in path).

    Args:
        cache_dir: Base directory for cache storage.
        embedding_model: Model name (used in cache path for auto-invalidation).
        size_limit: Maximum cache size in bytes (default 10GB).

    Example:
        >>> cache = EmbeddingCache(Path("data/cache"), "text-embedding-3-small")
        >>> cache.set("Hello world", [0.1, 0.2, ...])
        >>> embedding = cache.get("Hello world")  # Returns cached embedding
        >>> embedding = cache.get("Unknown text")  # Returns None
    """

    def __init__(
        self,
        cache_dir: Path,
        embedding_model: str,
        size_limit: int = 10 * 1024 * 1024 * 1024,  # 10GB default
    ) -> None:
        """Initialize cache with model-specific namespace."""
        # Model version in cache path ensures auto-invalidation on model change
        model_safe = embedding_model.replace("/", "_").replace(":", "_")
        self.cache_path = cache_dir / model_safe
        self.cache_path.mkdir(parents=True, exist_ok=True)
        self.cache = Cache(str(self.cache_path), size_limit=size_limit)
        self.embedding_model = embedding_model

    def _hash_content(self, text: str) -> str:
        """
        Generate SHA-256 hash of normalized text.

        Normalization: strip whitespace, collapse multiple spaces.
        This ensures "Hello  world" and "Hello world" map to same cache key.
        """
        normalized = " ".join(text.split())
        return hashlib.sha256(normalized.encode("utf-8")).hexdigest()

    def get(self, text: str) -> list[float] | None:
        """
        Retrieve cached embedding by content hash.

        Args:
            text: Original text content.

        Returns:
            Cached embedding vector, or None if not cached.
        """
        key = self._hash_content(text)
        return self.cache.get(key)

    def set(self, text: str, embedding: list[float]) -> None:
        """
        Store embedding with content hash key.

        Args:
            text: Original text content.
            embedding: Embedding vector to cache.
        """
        key = self._hash_content(text)
        self.cache.set(key, embedding)

    def contains(self, text: str) -> bool:
        """Check if text content is cached."""
        key = self._hash_content(text)
        return key in self.cache

    def stats(self) -> dict[str, object]:
        """
        Get cache statistics.

        Returns:
            Dict with size, disk_usage_mb, model, hits, misses.
        """
        return {
            "size": len(self.cache),
            "disk_usage_mb": round(self.cache.volume() / (1024 * 1024), 2),
            "model": self.embedding_model,
        }

    def clear(self) -> None:
        """Clear all cached embeddings."""
        self.cache.clear()

    def close(self) -> None:
        """Close cache connection."""
        self.cache.close()
```

Update `src/knowledge_mcp/embed/__init__.py` to export EmbeddingCache:
```python
from knowledge_mcp.embed.cache import EmbeddingCache

__all__ = ["EmbeddingCache"]
```
  </action>
  <verify>`poetry run python -c "from knowledge_mcp.embed import EmbeddingCache; print('OK')"` succeeds</verify>
  <done>EmbeddingCache class implemented with content hashing, model-versioned paths, and stats</done>
</task>

<task type="auto">
  <name>Task 2: Create unit tests for EmbeddingCache</name>
  <files>mcps/knowledge-mcp/tests/unit/test_embed_cache.py</files>
  <action>
Create `tests/unit/test_embed_cache.py` with comprehensive tests:

```python
"""Unit tests for EmbeddingCache."""

from __future__ import annotations

import tempfile
from pathlib import Path

import pytest

from knowledge_mcp.embed.cache import EmbeddingCache


class TestEmbeddingCache:
    """Tests for EmbeddingCache class."""

    @pytest.fixture
    def cache_dir(self) -> Path:
        """Create temporary cache directory."""
        with tempfile.TemporaryDirectory() as tmpdir:
            yield Path(tmpdir)

    @pytest.fixture
    def cache(self, cache_dir: Path) -> EmbeddingCache:
        """Create cache instance for testing."""
        return EmbeddingCache(cache_dir, "text-embedding-3-small")

    def test_set_and_get_embedding(self, cache: EmbeddingCache) -> None:
        """Test storing and retrieving embedding."""
        text = "Hello world"
        embedding = [0.1, 0.2, 0.3]

        cache.set(text, embedding)
        result = cache.get(text)

        assert result == embedding

    def test_get_missing_returns_none(self, cache: EmbeddingCache) -> None:
        """Test that missing text returns None."""
        result = cache.get("nonexistent text")
        assert result is None

    def test_normalized_text_matches(self, cache: EmbeddingCache) -> None:
        """Test that whitespace variations map to same cache entry."""
        embedding = [0.1, 0.2, 0.3]

        cache.set("Hello world", embedding)

        # Extra spaces should still hit cache
        assert cache.get("Hello  world") == embedding
        assert cache.get("  Hello world  ") == embedding
        assert cache.get("Hello\n\tworld") == embedding

    def test_different_text_different_keys(self, cache: EmbeddingCache) -> None:
        """Test that different text produces different cache keys."""
        cache.set("Hello world", [0.1])
        cache.set("Hello universe", [0.2])

        assert cache.get("Hello world") == [0.1]
        assert cache.get("Hello universe") == [0.2]

    def test_contains_check(self, cache: EmbeddingCache) -> None:
        """Test contains() method."""
        cache.set("cached text", [0.1])

        assert cache.contains("cached text") is True
        assert cache.contains("uncached text") is False

    def test_stats_returns_metrics(self, cache: EmbeddingCache) -> None:
        """Test stats() returns cache metrics."""
        cache.set("text1", [0.1])
        cache.set("text2", [0.2])

        stats = cache.stats()

        assert stats["size"] == 2
        assert stats["model"] == "text-embedding-3-small"
        assert "disk_usage_mb" in stats

    def test_clear_removes_all(self, cache: EmbeddingCache) -> None:
        """Test clear() removes all cached entries."""
        cache.set("text1", [0.1])
        cache.set("text2", [0.2])

        cache.clear()

        assert cache.get("text1") is None
        assert cache.get("text2") is None
        assert cache.stats()["size"] == 0

    def test_model_isolation(self, cache_dir: Path) -> None:
        """Test that different models have separate caches."""
        cache1 = EmbeddingCache(cache_dir, "model-v1")
        cache2 = EmbeddingCache(cache_dir, "model-v2")

        cache1.set("text", [0.1])

        # Different model should NOT see cache from other model
        assert cache1.get("text") == [0.1]
        assert cache2.get("text") is None

    def test_persistence_across_instances(self, cache_dir: Path) -> None:
        """Test that cache persists across instance recreation."""
        model = "text-embedding-3-small"

        # Create, populate, close
        cache1 = EmbeddingCache(cache_dir, model)
        cache1.set("persistent text", [0.1, 0.2])
        cache1.close()

        # Recreate and verify
        cache2 = EmbeddingCache(cache_dir, model)
        result = cache2.get("persistent text")

        assert result == [0.1, 0.2]
```

Run tests:
```bash
cd mcps/knowledge-mcp && poetry run pytest tests/unit/test_embed_cache.py -v
```
  </action>
  <verify>`poetry run pytest tests/unit/test_embed_cache.py -v` shows all tests passing</verify>
  <done>10+ unit tests covering cache operations, normalization, model isolation, persistence</done>
</task>

</tasks>

<verification>
Run verification sequence:
```bash
cd mcps/knowledge-mcp

# 1. Import test
poetry run python -c "from knowledge_mcp.embed import EmbeddingCache; print('Import: OK')"

# 2. Basic functionality test
poetry run python -c "
from pathlib import Path
import tempfile
from knowledge_mcp.embed import EmbeddingCache

with tempfile.TemporaryDirectory() as d:
    cache = EmbeddingCache(Path(d), 'test-model')
    cache.set('hello', [0.1, 0.2])
    result = cache.get('hello')
    assert result == [0.1, 0.2], f'Expected [0.1, 0.2], got {result}'
    print('Functionality: OK')
"

# 3. Run unit tests
poetry run pytest tests/unit/test_embed_cache.py -v

# 4. Run all tests (no regressions)
poetry run pytest tests/ -v --tb=short
```
</verification>

<success_criteria>
- [ ] EmbeddingCache class in src/knowledge_mcp/embed/cache.py
- [ ] Content hashing with SHA-256 (normalized text)
- [ ] Model-versioned cache paths for automatic invalidation
- [ ] get(), set(), contains(), stats(), clear(), close() methods
- [ ] 10+ unit tests all passing
- [ ] No regressions in existing tests
</success_criteria>

<output>
After completion, create `.planning/phases/04-production-readiness/04-02-SUMMARY.md`
</output>
