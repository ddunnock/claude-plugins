---
phase: 02-document-ingestion
plan: 05
type: execute
wave: 4
depends_on: ["02-04"]
files_modified:
  - mcps/knowledge-mcp/tests/integration/test_ingestion.py
  - mcps/knowledge-mcp/scripts/validate_ingestion.py
autonomous: false

must_haves:
  truths:
    - "PDF documents ingest with clause hierarchy preserved in metadata"
    - "Tables remain intact (visual comparison shows no mid-row splits)"
    - "Chunks include source, section, page, and clause metadata"
    - "Chunks tagged as normative vs informative where identifiable"
  artifacts:
    - path: "mcps/knowledge-mcp/tests/integration/test_ingestion.py"
      provides: "Integration tests for full ingestion flow"
      exports: []
    - path: "mcps/knowledge-mcp/scripts/validate_ingestion.py"
      provides: "CLI script for visual validation"
      exports: []
  key_links:
    - from: "test_ingestion.py"
      to: "IngestionPipeline"
      via: "integration tests"
      pattern: "IngestionPipeline"
---

<objective>
Validate the ingestion pipeline on sample documents and create integration tests. This plan includes a human checkpoint for visual verification of table integrity and clause preservation.

Purpose: NFR-2.3 requires validating PDF extraction on sample docs before bulk ingest. This plan ensures the pipeline works correctly on real documents and tables are not split mid-row.

Output: Integration tests, validation script, human-verified sample ingestion.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-document-ingestion/02-CONTEXT.md
@.planning/phases/02-document-ingestion/02-RESEARCH.md
@.planning/phases/02-document-ingestion/02-04-SUMMARY.md
@mcps/knowledge-mcp/src/knowledge_mcp/ingest/pipeline.py
@mcps/knowledge-mcp/src/knowledge_mcp/models/chunk.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create validation script for visual inspection</name>
  <files>
    mcps/knowledge-mcp/scripts/validate_ingestion.py
  </files>
  <action>
Create `scripts/validate_ingestion.py` CLI script that:

1. Takes a document path as argument
2. Runs IngestionPipeline on the document
3. Outputs detailed report to stdout:
   - Document metadata (title, type, source_path)
   - Total chunks created
   - Token count statistics (min, max, avg, total)
   - Chunks by type (text, table, list)
   - Normative vs informative count

4. For each table chunk, outputs:
   - Chunk ID
   - Page number(s)
   - Section/clause
   - First 3 rows of table content (markdown formatted)
   - "Table continues..." indicator if truncated

5. For sample text chunks (first 3), outputs:
   - Chunk ID
   - Section hierarchy
   - Clause number
   - Normative status
   - First 200 characters of content
   - Whether chunk has overlap from previous

Use rich library for formatted console output.
Use argparse for CLI interface:
```
python -m scripts.validate_ingestion path/to/document.pdf [--verbose] [--tables-only]
```
  </action>
  <verify>
`poetry run python mcps/knowledge-mcp/scripts/validate_ingestion.py --help` shows usage.
Script runs without errors (will test with real doc in checkpoint).
  </verify>
  <done>Validation script created for visual inspection of ingested documents.</done>
</task>

<task type="auto">
  <name>Task 2: Create integration tests for ingestion pipeline</name>
  <files>
    mcps/knowledge-mcp/tests/integration/__init__.py
    mcps/knowledge-mcp/tests/integration/test_ingestion.py
  </files>
  <action>
Create `tests/integration/test_ingestion.py` with tests that use REAL Docling processing:

1. Test small PDF ingestion:
   - Create a simple test PDF fixture (or use a publicly available small PDF)
   - Verify chunks are created
   - Verify token counts are within limits (<=1000)
   - Verify metadata is populated

2. Test table extraction integrity:
   - If test PDF has tables, verify table_data is list[list[str]]
   - Verify no chunk has partial row (all rows in chunk have same column count)
   - Verify table caption is preserved

3. Test section hierarchy preservation:
   - Verify section_hierarchy is list with at least one element for structured docs
   - Verify clause_number is extracted when present

4. Test normative detection in real content:
   - Chunks containing "shall" should have normative=True
   - Chunks containing only "NOTE:" should have normative=False

5. Test error handling:
   - Non-existent file raises IngestionError
   - Invalid PDF (corrupted) raises IngestionError with message

Mark integration tests with `@pytest.mark.integration` to allow skipping in quick CI runs.

Create `tests/integration/__init__.py`.
  </action>
  <verify>
`poetry run pytest mcps/knowledge-mcp/tests/integration/test_ingestion.py -v -m integration` passes.
(May need to skip if no test fixtures available - tests should skip gracefully.)
  </verify>
  <done>Integration tests validate real Docling processing, table integrity, and metadata extraction.</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Complete document ingestion pipeline:
- PDF and DOCX ingestors using Docling
- Hierarchical chunker with 500 token target, 20% overlap
- Normative/informative detection
- Full metadata extraction (source, section, page, clause)
  </what-built>
  <how-to-verify>
1. Provide a sample PDF document (engineering standard if available, or any structured PDF with tables)

2. Run the validation script:
   ```bash
   cd mcps/knowledge-mcp
   poetry run python scripts/validate_ingestion.py /path/to/your/document.pdf --verbose
   ```

3. Review the output and verify:
   - [ ] Document metadata is correctly extracted
   - [ ] Chunks have reasonable token counts (most 300-600, none over 1000)
   - [ ] Section hierarchy shows clause numbers (e.g., ["4", "4.2", "4.2.3"])
   - [ ] Tables show with column headers intact
   - [ ] No table appears to be split mid-row (rows have consistent column counts)
   - [ ] Normative chunks correctly identified (contain SHALL/MUST)
   - [ ] Page numbers are present

4. If issues found, describe what's wrong and I'll create fixes.
  </how-to-verify>
  <resume-signal>Type "approved" if ingestion looks correct, or describe issues to fix.</resume-signal>
</task>

</tasks>

<verification>
Overall plan verification:
```bash
cd mcps/knowledge-mcp
poetry run pytest tests/integration/test_ingestion.py -v -m integration
poetry run python scripts/validate_ingestion.py --help
```
</verification>

<success_criteria>
1. Validation script provides clear visual inspection of ingested documents
2. Integration tests verify real Docling processing (not mocked)
3. Human verification confirms:
   - Tables are intact (no mid-row splits)
   - Clause hierarchy is preserved
   - Metadata is complete (source, section, page, clause)
   - Normative detection is reasonable
4. NFR-2.3 satisfied: PDF extraction validated on sample docs
</success_criteria>

<output>
After completion, create `.planning/phases/02-document-ingestion/02-05-SUMMARY.md`
</output>
