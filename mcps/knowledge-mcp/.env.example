# =============================================================================
# Knowledge MCP Configuration
# =============================================================================
# Copy this file to .env and fill in your values

# -----------------------------------------------------------------------------
# OpenAI API (REQUIRED for embeddings)
# -----------------------------------------------------------------------------
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-api-key-here

# -----------------------------------------------------------------------------
# Embedding Model Configuration
# -----------------------------------------------------------------------------
# Options:
#   text-embedding-3-small - $0.02/1M tokens, 1536 dimensions (recommended)
#   text-embedding-3-large - $0.13/1M tokens, 3072 dimensions (higher quality)
#   text-embedding-ada-002 - $0.10/1M tokens, 1536 dimensions (legacy)
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_DIMENSIONS=1536

# -----------------------------------------------------------------------------
# Vector Store Configuration
# -----------------------------------------------------------------------------
# Options: qdrant (recommended), chromadb (local fallback)
VECTOR_STORE=qdrant

# -----------------------------------------------------------------------------
# Qdrant Cloud Settings (PRIMARY - Free Tier)
# -----------------------------------------------------------------------------
# Sign up at: https://cloud.qdrant.io/
# 1. Create a free cluster (1GB, no credit card required)
# 2. Copy the cluster URL and API key
#
# Cluster URL format: https://<cluster-id>.<region>.gcp.cloud.qdrant.io
# Example: https://abc123-xyz.us-east4-0.gcp.cloud.qdrant.io
QDRANT_URL=https://your-cluster-id.region.gcp.cloud.qdrant.io

# API Key (from Qdrant Cloud dashboard → Data Access Control → API Keys)
QDRANT_API_KEY=your-api-key-here

# Collection name for the knowledge base
QDRANT_COLLECTION=se_knowledge_base

# Enable hybrid search (dense + sparse vectors for better retrieval)
QDRANT_HYBRID_SEARCH=true

# -----------------------------------------------------------------------------
# ChromaDB Settings (LOCAL FALLBACK)
# -----------------------------------------------------------------------------
# Used when VECTOR_STORE=chromadb or for offline development
CHROMADB_PATH=./collections/chromadb
CHROMADB_COLLECTION=se_knowledge_base

# -----------------------------------------------------------------------------
# Chunking Configuration
# -----------------------------------------------------------------------------
# Minimum chunk size in tokens (don't create chunks smaller than this)
CHUNK_SIZE_MIN=200
# Maximum chunk size in tokens (split chunks larger than this)
CHUNK_SIZE_MAX=800
# Overlap between chunks in tokens (for context continuity)
CHUNK_OVERLAP=100

# -----------------------------------------------------------------------------
# Document Processing
# -----------------------------------------------------------------------------
# Path to source documents (PDFs, DOCX, MD)
SOURCES_PATH=./data/sources
# Path for processed/intermediate files
PROCESSED_PATH=./data/processed

# -----------------------------------------------------------------------------
# Logging
# -----------------------------------------------------------------------------
# Options: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# -----------------------------------------------------------------------------
# Optional: Reranking (Cohere) - Improves result quality
# -----------------------------------------------------------------------------
# Cohere API key for reranking (https://dashboard.cohere.com/api-keys)
COHERE_API_KEY=
# Enable reranking (increases latency but improves relevance)
USE_RERANKING=false

# -----------------------------------------------------------------------------
# Optional: Local Embedding Model (for offline use)
# -----------------------------------------------------------------------------
# Use a local sentence-transformer model instead of OpenAI
# Options: all-MiniLM-L6-v2, all-mpnet-base-v2, multi-qa-mpnet-base-dot-v1
USE_LOCAL_EMBEDDINGS=false
LOCAL_EMBEDDING_MODEL=all-MiniLM-L6-v2
