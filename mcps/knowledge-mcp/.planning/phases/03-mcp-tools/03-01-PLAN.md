---
phase: 03-mcp-tools
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/knowledge_mcp/server.py
  - tests/unit/test_server.py
autonomous: true

must_haves:
  truths:
    - "knowledge_search tool returns real search results when called via MCP protocol"
    - "knowledge_stats tool returns collection statistics (document count, chunk count)"
    - "MCP server starts successfully via python -m knowledge_mcp"
    - "Tool errors return structured error responses with isError: true"
  artifacts:
    - path: "src/knowledge_mcp/server.py"
      provides: "MCP tool handlers for knowledge_search and knowledge_stats"
      exports: ["KnowledgeMCPServer"]
    - path: "tests/unit/test_server.py"
      provides: "Unit tests for MCP tool handlers"
      min_lines: 80
  key_links:
    - from: "src/knowledge_mcp/server.py"
      to: "SemanticSearcher"
      via: "dependency injection in constructor"
      pattern: "SemanticSearcher"
    - from: "src/knowledge_mcp/server.py"
      to: "BaseStore.get_stats"
      via: "asyncio.to_thread for sync method"
      pattern: "asyncio\\.to_thread.*get_stats"
    - from: "tests/unit/test_server.py"
      to: "handle_call_tool"
      via: "mock embedder and store"
      pattern: "(AsyncMock|MagicMock)"
---

<objective>
Implement working MCP tool handlers that expose semantic search and statistics functionality.

Purpose: Transform the skeleton MCP server into a functional knowledge search interface that Claude and other LLM clients can use via the MCP protocol.

Output: Complete MCP server with knowledge_search and knowledge_stats tools, plus comprehensive unit tests.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Prior phase context
@.planning/phases/02-search-layer/02-01-SUMMARY.md

# Relevant source files
@src/knowledge_mcp/server.py
@src/knowledge_mcp/search/semantic_search.py
@src/knowledge_mcp/search/models.py
@src/knowledge_mcp/store/base.py
@src/knowledge_mcp/embed/base.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add dependency injection and tool definitions to server</name>
  <files>src/knowledge_mcp/server.py</files>
  <action>
Update KnowledgeMCPServer to accept dependencies and define tools:

1. **Constructor changes:**
   - Add optional parameters: `embedder: BaseEmbedder | None = None`, `store: BaseStore | None = None`
   - If not provided, create from config using `load_config()`, `OpenAIEmbedder`, `create_store()`
   - Create `SemanticSearcher(embedder, store)` instance and store as `self._searcher`
   - Store `self._store` for stats access
   - Lazy initialization: only create real dependencies when server runs (not in tests)

2. **Tool definitions in list_tools:**
   Import `Tool` from `mcp.types` (not TYPE_CHECKING block).
   Return list with two tools:

   ```python
   Tool(
       name="knowledge_search",
       description="Search the systems engineering knowledge base for relevant standards, requirements, and guidance. Returns ranked results with source citations.",
       inputSchema={
           "type": "object",
           "properties": {
               "query": {
                   "type": "string",
                   "description": "Natural language search query (e.g., 'system requirements review process')"
               },
               "n_results": {
                   "type": "integer",
                   "description": "Maximum results to return (1-50)",
                   "default": 10,
                   "minimum": 1,
                   "maximum": 50
               },
               "document_type": {
                   "type": "string",
                   "description": "Filter by document type (standard, handbook, guide)",
                   "enum": ["standard", "handbook", "guide"]
               }
           },
           "required": ["query"]
       }
   ),
   Tool(
       name="knowledge_stats",
       description="Get statistics about the knowledge base including document count, chunk count, and collection info.",
       inputSchema={
           "type": "object",
           "properties": {},
           "required": []
       }
   )
   ```

3. **Import updates:**
   - Add: `from knowledge_mcp.search import SemanticSearcher`
   - Add: `from knowledge_mcp.store import create_store, BaseStore`
   - Add: `from knowledge_mcp.embed import OpenAIEmbedder, BaseEmbedder`
   - Add: `from knowledge_mcp.utils.config import load_config`
   - Move `Tool` import out of TYPE_CHECKING block

4. **IMPORTANT - Never use print():**
   Remove the `print("\nInterrupted by user"...)` from `__main__.py`. Use `sys.stderr.write()` or logging instead, as print() corrupts the JSON-RPC protocol.
  </action>
  <verify>
    - `poetry run pyright src/knowledge_mcp/server.py` passes with zero errors
    - `poetry run python -c "from knowledge_mcp.server import KnowledgeMCPServer; print('import OK')"`
  </verify>
  <done>
    - KnowledgeMCPServer accepts optional embedder/store for testing
    - list_tools returns knowledge_search and knowledge_stats definitions
    - All imports resolve correctly
    - No print() statements in server code path
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement call_tool handlers with error handling</name>
  <files>src/knowledge_mcp/server.py</files>
  <action>
Replace the stub call_tool handler with real implementations:

1. **knowledge_search handler:**
   ```python
   async def _handle_knowledge_search(self, arguments: dict[str, Any]) -> list[TextContent]:
       query = arguments.get("query", "")
       n_results = arguments.get("n_results", 10)
       document_type = arguments.get("document_type")

       # Build filter dict if document_type provided
       filter_dict = {"document_type": document_type} if document_type else None

       results = await self._searcher.search(
           query=query,
           n_results=min(n_results, 50),  # Cap at 50
           filter_dict=filter_dict,
       )

       # Format results for LLM consumption
       formatted = [
           {
               "score": r.score,
               "content": r.content,
               "source": {
                   "document": r.document_title,
                   "section": r.section_title,
                   "clause": r.clause_number,
                   "type": r.document_type,
                   "normative": r.normative,
               }
           }
           for r in results
       ]

       return [TextContent(type="text", text=json.dumps(formatted, indent=2))]
   ```

2. **knowledge_stats handler:**
   ```python
   async def _handle_knowledge_stats(self) -> list[TextContent]:
       # get_stats is sync, wrap in asyncio.to_thread
       stats = await asyncio.to_thread(self._store.get_stats)
       return [TextContent(type="text", text=json.dumps(stats, indent=2))]
   ```

3. **Error handling wrapper:**
   ```python
   async def _safe_call(self, handler: Callable[..., Awaitable[list[TextContent]]], *args) -> list[TextContent]:
       try:
           return await handler(*args)
       except Exception as e:
           error_response = {"error": str(e), "isError": True}
           return [TextContent(type="text", text=json.dumps(error_response))]
   ```

4. **Update handle_call_tool to dispatch:**
   ```python
   @self.server.call_tool()
   async def handle_call_tool(name: str, arguments: dict[str, Any]) -> list[TextContent]:
       if name == "knowledge_search":
           return await self._safe_call(self._handle_knowledge_search, arguments)
       elif name == "knowledge_stats":
           return await self._safe_call(self._handle_knowledge_stats)
       else:
           return [TextContent(
               type="text",
               text=json.dumps({"error": f"Unknown tool: {name}", "isError": True})
           )]
   ```

5. **Import additions:**
   - Add: `import asyncio`
   - Add: `import json`
   - Add: `from typing import Callable, Awaitable`
  </action>
  <verify>
    - `poetry run pyright src/knowledge_mcp/server.py` passes with zero errors
    - `poetry run pytest -xvs` all tests pass
  </verify>
  <done>
    - knowledge_search handler calls SemanticSearcher and returns formatted JSON
    - knowledge_stats handler calls store.get_stats wrapped in asyncio.to_thread
    - Errors are caught and returned with isError: true
    - Unknown tools return error response (not exception)
  </done>
</task>

<task type="auto">
  <name>Task 3: Create unit tests for MCP tool handlers</name>
  <files>tests/unit/test_server.py</files>
  <action>
Create comprehensive unit tests for the MCP server:

1. **Create test file structure:**
   ```python
   """Unit tests for MCP server tool handlers."""

   from __future__ import annotations

   import json
   from unittest.mock import AsyncMock, MagicMock

   import pytest

   from knowledge_mcp.server import KnowledgeMCPServer
   from knowledge_mcp.search.models import SearchResult
   ```

2. **Fixtures:**
   ```python
   @pytest.fixture
   def mock_embedder() -> MagicMock:
       embedder = MagicMock()
       embedder.embed = AsyncMock(return_value=[0.1] * 1536)
       embedder.dimensions = 1536
       return embedder

   @pytest.fixture
   def mock_store() -> MagicMock:
       store = MagicMock()
       store.search.return_value = [
           {
               "id": "chunk-1",
               "content": "Test content about SRR",
               "score": 0.95,
               "metadata": {
                   "document_title": "IEEE 15288",
                   "section_title": "System Requirements Review",
                   "document_type": "standard",
                   "normative": True,
                   "clause_number": "5.3.1",
               }
           }
       ]
       store.get_stats.return_value = {
           "collection_name": "test_collection",
           "total_chunks": 1000,
           "vectors_count": 1000,
       }
       store.health_check.return_value = True
       return store

   @pytest.fixture
   def server(mock_embedder: MagicMock, mock_store: MagicMock) -> KnowledgeMCPServer:
       return KnowledgeMCPServer(embedder=mock_embedder, store=mock_store)
   ```

3. **Test list_tools:**
   ```python
   class TestListTools:
       @pytest.mark.asyncio
       async def test_returns_two_tools(self, server: KnowledgeMCPServer) -> None:
           # Get the registered handler
           tools = await server.server._tool_handlers["list_tools"]()
           assert len(tools) == 2
           assert tools[0].name == "knowledge_search"
           assert tools[1].name == "knowledge_stats"

       @pytest.mark.asyncio
       async def test_knowledge_search_has_required_query(self, server: KnowledgeMCPServer) -> None:
           tools = await server.server._tool_handlers["list_tools"]()
           search_tool = tools[0]
           assert "query" in search_tool.inputSchema["required"]
   ```

4. **Test knowledge_search:**
   ```python
   class TestKnowledgeSearch:
       @pytest.mark.asyncio
       async def test_returns_formatted_results(
           self, server: KnowledgeMCPServer, mock_embedder: MagicMock
       ) -> None:
           result = await server.server._tool_handlers["call_tool"](
               "knowledge_search", {"query": "SRR process"}
           )
           assert len(result) == 1
           data = json.loads(result[0].text)
           assert len(data) == 1
           assert data[0]["score"] == 0.95
           assert data[0]["source"]["document"] == "IEEE 15288"

       @pytest.mark.asyncio
       async def test_applies_document_type_filter(
           self, server: KnowledgeMCPServer, mock_store: MagicMock
       ) -> None:
           await server.server._tool_handlers["call_tool"](
               "knowledge_search", {"query": "test", "document_type": "standard"}
           )
           mock_store.search.assert_called_once()
           # SemanticSearcher transforms this to filter_dict

       @pytest.mark.asyncio
       async def test_caps_n_results_at_50(
           self, server: KnowledgeMCPServer, mock_embedder: MagicMock
       ) -> None:
           await server.server._tool_handlers["call_tool"](
               "knowledge_search", {"query": "test", "n_results": 100}
           )
           # Verify n_results was capped (check via mock)
   ```

5. **Test knowledge_stats:**
   ```python
   class TestKnowledgeStats:
       @pytest.mark.asyncio
       async def test_returns_stats(self, server: KnowledgeMCPServer) -> None:
           result = await server.server._tool_handlers["call_tool"](
               "knowledge_stats", {}
           )
           data = json.loads(result[0].text)
           assert data["total_chunks"] == 1000
   ```

6. **Test error handling:**
   ```python
   class TestErrorHandling:
       @pytest.mark.asyncio
       async def test_unknown_tool_returns_error(self, server: KnowledgeMCPServer) -> None:
           result = await server.server._tool_handlers["call_tool"](
               "unknown_tool", {}
           )
           data = json.loads(result[0].text)
           assert data["isError"] is True
           assert "Unknown tool" in data["error"]

       @pytest.mark.asyncio
       async def test_search_error_returns_is_error(
           self, server: KnowledgeMCPServer, mock_embedder: MagicMock
       ) -> None:
           mock_embedder.embed.side_effect = Exception("API error")
           result = await server.server._tool_handlers["call_tool"](
               "knowledge_search", {"query": "test"}
           )
           data = json.loads(result[0].text)
           # SemanticSearcher returns empty list on error, not exception
           # So this test should verify empty results, not isError
           assert isinstance(data, list)
   ```
  </action>
  <verify>
    - `poetry run pytest tests/unit/test_server.py -xvs` all tests pass
    - `poetry run pytest --cov=src/knowledge_mcp/server --cov-report=term-missing` shows coverage
  </verify>
  <done>
    - tests/unit/test_server.py exists with 8+ test cases
    - Tests cover: list_tools, knowledge_search, knowledge_stats, error handling
    - All tests pass with mocked dependencies
    - Server code has test coverage
  </done>
</task>

</tasks>

<verification>
After all tasks complete:

1. **Type checking:**
   ```bash
   poetry run pyright src/knowledge_mcp/server.py
   # Expected: 0 errors
   ```

2. **All tests pass:**
   ```bash
   poetry run pytest -xvs
   # Expected: All tests pass including new server tests
   ```

3. **Server starts (but will fail without config - that's OK):**
   ```bash
   timeout 2 poetry run python -m knowledge_mcp 2>&1 || true
   # Expected: Starts and waits for input (or config error, not import error)
   ```

4. **Tool definitions are correct:**
   ```bash
   poetry run python -c "
   from knowledge_mcp.server import KnowledgeMCPServer
   from unittest.mock import MagicMock
   s = KnowledgeMCPServer(embedder=MagicMock(), store=MagicMock())
   import asyncio
   tools = asyncio.run(s.server._tool_handlers['list_tools']())
   print(f'Tools: {[t.name for t in tools]}')
   assert len(tools) == 2
   print('OK')
   "
   ```
</verification>

<success_criteria>
1. `knowledge_search` tool returns formatted search results with source citations
2. `knowledge_stats` tool returns collection statistics
3. `python -m knowledge_mcp` starts without import errors
4. Unknown tools return `{"error": "...", "isError": true}`
5. All tests pass including new server tests
6. Zero pyright errors
</success_criteria>

<output>
After completion, create `.planning/phases/03-mcp-tools/03-01-SUMMARY.md`
</output>
