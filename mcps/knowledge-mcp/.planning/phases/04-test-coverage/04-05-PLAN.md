---
phase: 04-test-coverage
plan: 05
type: execute
wave: 1
depends_on: []
files_modified:
  - tests/integration/test_mcp_tools.py
  - tests/integration/__init__.py
autonomous: true
user_setup: []

must_haves:
  truths:
    - "knowledge_search tool tested through full call chain (embedder -> store -> search -> format)"
    - "knowledge_stats tool tested through full call chain (store -> stats -> format)"
    - "MCP tool handlers exercise real SemanticSearcher with real store (ChromaDB local)"
  artifacts:
    - path: "tests/integration/test_mcp_tools.py"
      provides: "Integration tests for MCP tool handlers"
      min_lines: 100
      contains: "TestMCPToolIntegration"
    - path: "tests/integration/__init__.py"
      provides: "Integration test package init"
  key_links:
    - from: "tests/integration/test_mcp_tools.py"
      to: "src/knowledge_mcp/server.py"
      via: "tests KnowledgeMCPServer with real dependencies"
      pattern: "KnowledgeMCPServer"
    - from: "tests/integration/test_mcp_tools.py"
      to: "src/knowledge_mcp/search/semantic_search.py"
      via: "exercises SemanticSearcher through MCP call"
      pattern: "knowledge_search"
---

<objective>
Add integration tests for MCP tool handlers that test through the full call chain.

Purpose: The existing unit tests in test_server.py use mocked dependencies. This plan adds integration tests that exercise the real code path: MCP handler -> SemanticSearcher -> real store (ChromaDB). This fulfills Success Criteria #3: "All MCP tool handlers have integration tests."

Output: Integration test file covering knowledge_search and knowledge_stats through real dependencies.
</objective>

<execution_context>
@/Users/dunnock/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dunnock/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

Key files:
@src/knowledge_mcp/server.py
@src/knowledge_mcp/search/semantic_search.py
@src/knowledge_mcp/store/chromadb_store.py
@tests/unit/test_server.py
@tests/conftest.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create MCP tool integration tests</name>
  <files>tests/integration/__init__.py, tests/integration/test_mcp_tools.py</files>
  <action>
Create integration tests for MCP tool handlers with real dependencies (ChromaDB local).

1. Ensure `tests/integration/__init__.py` exists (may already exist)

2. Create `tests/integration/test_mcp_tools.py` with:

**Fixtures:**
- `temp_chromadb_dir` - pytest tmp_path for ChromaDB storage
- `test_config` - KnowledgeConfig with ChromaDB backend and mock OpenAI key
- `mock_openai_embedder` - Real OpenAIEmbedder but with mocked API calls (to avoid hitting OpenAI)
- `real_chromadb_store` - Real ChromaDBStore instance with test data
- `server_with_real_deps` - KnowledgeMCPServer with real store but mocked embedder

**Test Class: TestMCPToolIntegration**

Setup:
- Create a ChromaDBStore with test collection
- Add a few test chunks with known content and embeddings
- Create KnowledgeMCPServer with real store and mocked embedder (mock embedder to avoid API calls)

Tests:
- `test_knowledge_search_returns_real_results` - verify search returns actual chunks from ChromaDB
- `test_knowledge_search_filter_works` - verify filter_dict actually filters results
- `test_knowledge_search_score_threshold_works` - verify low-score results are excluded
- `test_knowledge_stats_returns_real_count` - verify stats.total_chunks matches actual count
- `test_knowledge_search_empty_collection` - verify empty results from empty collection
- `test_full_search_flow_with_embedding` - test embedding -> store search -> format results

**Pattern:**
```python
import pytest
from pathlib import Path
from unittest.mock import AsyncMock, patch
from mcp.types import CallToolRequest

from knowledge_mcp.server import KnowledgeMCPServer
from knowledge_mcp.store.chromadb_store import ChromaDBStore
from knowledge_mcp.embed import OpenAIEmbedder
from knowledge_mcp.models.chunk import KnowledgeChunk
from knowledge_mcp.utils.config import KnowledgeConfig


class TestMCPToolIntegration:
    """Integration tests for MCP tools with real ChromaDB store."""

    @pytest.fixture
    def test_config(self, tmp_path: Path) -> KnowledgeConfig:
        """Create config for integration tests."""
        return KnowledgeConfig(
            openai_api_key="test-key",  # Will be mocked
            vector_store="chromadb",
            chromadb_path=tmp_path / "chromadb",
        )

    @pytest.fixture
    def real_store(self, test_config: KnowledgeConfig) -> ChromaDBStore:
        """Create real ChromaDB store with test data."""
        store = ChromaDBStore(test_config)

        # Add test chunks with known embeddings
        test_chunks = [
            KnowledgeChunk(
                id="chunk-1",
                content="System requirements review is a key milestone",
                document_id="ieee-15288",
                document_title="IEEE 15288.2",
                document_type="standard",
                section_title="SRR",
                section_hierarchy=["5", "5.3"],
                chunk_type="requirement",
                normative=True,
                embedding=[0.1] * 1536,  # Known embedding
            ),
            KnowledgeChunk(
                id="chunk-2",
                content="Configuration management ensures traceability",
                document_id="ieee-828",
                document_title="IEEE 828",
                document_type="standard",
                section_title="CM",
                section_hierarchy=["4"],
                chunk_type="guidance",
                normative=False,
                embedding=[0.2] * 1536,
            ),
        ]
        store.add_chunks(test_chunks)
        return store

    @pytest.fixture
    def mock_embedder(self) -> AsyncMock:
        """Create mock embedder that returns predictable embeddings."""
        embedder = AsyncMock()
        # Return embedding similar to chunk-1 for search
        embedder.embed.return_value = [0.1] * 1536
        return embedder

    @pytest.fixture
    def server(
        self,
        mock_embedder: AsyncMock,
        real_store: ChromaDBStore,
    ) -> KnowledgeMCPServer:
        """Create server with real store but mocked embedder."""
        return KnowledgeMCPServer(
            name="test-integration",
            embedder=mock_embedder,
            store=real_store,
        )

    @pytest.mark.asyncio
    async def test_knowledge_search_returns_real_results(
        self,
        server: KnowledgeMCPServer,
    ) -> None:
        """Test that search returns actual chunks from ChromaDB."""
        # Arrange
        request = CallToolRequest(
            params={"name": "knowledge_search", "arguments": {"query": "system requirements"}}
        )

        # Act
        response = await server.server.request_handlers[CallToolRequest](request)

        # Assert
        import json
        data = json.loads(response.root.content[0].text)
        assert data["total_results"] >= 1
        # Should find the SRR chunk
        contents = [r["content"] for r in data["results"]]
        assert any("System requirements review" in c for c in contents)

    @pytest.mark.asyncio
    async def test_knowledge_stats_returns_real_count(
        self,
        server: KnowledgeMCPServer,
    ) -> None:
        """Test that stats returns actual chunk count from ChromaDB."""
        # Arrange
        request = CallToolRequest(params={"name": "knowledge_stats", "arguments": {}})

        # Act
        response = await server.server.request_handlers[CallToolRequest](request)

        # Assert
        import json
        data = json.loads(response.root.content[0].text)
        assert data["total_chunks"] == 2  # We added 2 test chunks
```

**Key differences from unit tests:**
- Uses real ChromaDBStore, not MagicMock
- Chunks are actually stored and retrieved
- Tests verify the full integration: MCP handler -> SemanticSearcher -> Store -> ChromaDB
- Only the OpenAI embedder is mocked (to avoid API calls and costs)
  </action>
  <verify>
```bash
poetry run pytest tests/integration/test_mcp_tools.py -v
```
All integration tests should pass.
  </verify>
  <done>MCP tool handlers have integration tests exercising full call chain with real ChromaDB store.</done>
</task>

</tasks>

<verification>
```bash
# Run integration tests
poetry run pytest tests/integration/test_mcp_tools.py -v

# Run all integration tests together
poetry run pytest tests/integration/ -v

# Verify no regressions in unit tests
poetry run pytest tests/unit/test_server.py -v
```

All tests should pass.
</verification>

<success_criteria>
- tests/integration/test_mcp_tools.py exists with 5+ integration tests
- Tests use real ChromaDBStore (not mocked)
- Tests verify actual data flows through the system
- knowledge_search returns real results from ChromaDB
- knowledge_stats returns real counts from ChromaDB
- All tests pass
- Zero pyright errors in test files
</success_criteria>

<output>
After completion, create `.planning/phases/04-test-coverage/04-05-SUMMARY.md`
</output>
