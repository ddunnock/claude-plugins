---
phase: 05-extended-features
plan: 04
type: execute
wave: 2
depends_on: ["05-01"]
files_modified:
  - src/knowledge_mcp/cli/verify.py
  - src/knowledge_mcp/cli/main.py
  - tests/unit/test_cli/test_verify.py
autonomous: true

must_haves:
  truths:
    - "`knowledge verify` validates collection health"
    - "Verify shows chunk count, document count, dimensions"
    - "--embeddings flag validates dimension consistency"
    - "Errors produce clear exit codes and messages"
  artifacts:
    - path: "src/knowledge_mcp/cli/verify.py"
      provides: "Verify CLI command"
      exports: ["verify_command"]
      min_lines: 40
    - path: "tests/unit/test_cli/test_verify.py"
      provides: "Verify command tests"
      min_lines: 30
  key_links:
    - from: "src/knowledge_mcp/cli/main.py"
      to: "src/knowledge_mcp/cli/verify.py"
      via: "app.command() registration"
      pattern: "verify_command"
    - from: "src/knowledge_mcp/cli/verify.py"
      to: "src/knowledge_mcp/store"
      via: "create_store for collection access"
      pattern: "create_store"
---

<objective>
Implement `knowledge verify` CLI command for collection health validation.

Purpose: Allow users to check that their vector store collection is healthy and embeddings are consistent.
Output: Working verify command that reports collection statistics and validates embedding dimensions.
</objective>

<execution_context>
@/Users/dunnock/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dunnock/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-extended-features/05-CONTEXT.md
@.planning/phases/05-extended-features/05-01-SUMMARY.md
@src/knowledge_mcp/cli/main.py
@src/knowledge_mcp/store/__init__.py
@src/knowledge_mcp/utils/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement verify CLI command</name>
  <files>
    src/knowledge_mcp/cli/verify.py
    src/knowledge_mcp/cli/main.py
  </files>
  <action>
1. Create src/knowledge_mcp/cli/verify.py:

```python
"""Verify command for collection health checks."""
from __future__ import annotations

from typing import TYPE_CHECKING, Any

import typer
from rich.console import Console
from rich.table import Table

if TYPE_CHECKING:
    from knowledge_mcp.utils.config import KnowledgeConfig

console = Console()


def verify_command(
    collection: str = typer.Option(
        "knowledge",
        "--collection", "-c",
        help="Collection name to verify",
    ),
    check_embeddings: bool = typer.Option(
        False,
        "--embeddings", "-e",
        help="Verify embedding dimensions match",
    ),
) -> None:
    """Validate collection health and embeddings.

    Checks:
    - Collection exists and is accessible
    - Document and chunk counts
    - Embedding dimensions (if --embeddings flag)
    """
    import asyncio
    from knowledge_mcp.utils.config import load_config

    # Load config
    config = load_config()

    # Run async verification
    asyncio.run(_verify_async(collection, check_embeddings, config))


async def _verify_async(
    collection: str,
    check_embeddings: bool,
    config: KnowledgeConfig,
) -> None:
    """Async verification logic."""
    from knowledge_mcp.store import create_store

    console.print(f"\n[bold]Verifying collection:[/bold] {collection}\n")

    try:
        # Create store - use versioned collection name
        # Override collection name in config for this check
        store = create_store(config, collection_name=collection)

        # Get collection stats
        stats = store.get_collection_stats()

        # Display stats table
        table = Table(title="Collection Statistics")
        table.add_column("Metric", style="cyan")
        table.add_column("Value", justify="right")

        table.add_row("Collection", collection)
        table.add_row("Total Chunks", str(stats.get("total_points", "N/A")))
        table.add_row("Unique Documents", str(stats.get("unique_documents", "N/A")))
        table.add_row("Vector Dimensions", str(stats.get("vector_dimensions", "N/A")))

        console.print(table)

        # Check embedding dimensions if requested
        if check_embeddings:
            console.print("\n[bold]Embedding Verification:[/bold]")
            expected_dims = config.embedding_dimensions
            actual_dims = stats.get("vector_dimensions")

            if actual_dims is None:
                console.print("[yellow]UNKNOWN[/yellow] Could not determine collection dimensions")
            elif actual_dims == expected_dims:
                console.print(f"[green]OK[/green] Dimensions match ({actual_dims})")
            else:
                console.print(
                    f"[red]MISMATCH[/red] Expected {expected_dims}, found {actual_dims}"
                )
                console.print(
                    "[yellow]Warning:[/yellow] Dimension mismatch may cause search issues. "
                    "Consider re-ingesting with correct embedding model."
                )
                raise typer.Exit(1)

        console.print("\n[green]Verification complete.[/green]")

    except typer.Exit:
        raise
    except Exception as e:
        console.print(f"\n[red]Error:[/red] {e}")
        raise typer.Exit(1)
```

2. Update src/knowledge_mcp/cli/main.py to register verify command:
   - Import verify_command from verify module
   - Register with `app.command("verify")(verify_command)`

   Add after the ingest_app registration:
   ```python
   from knowledge_mcp.cli.verify import verify_command

   # Register verify command
   app.command("verify")(verify_command)
   ```

3. Verification checks:
   - Collection exists and is accessible
   - Returns chunk count and document count
   - Optionally validates embedding dimensions
   - Reports any errors clearly with exit code 1
  </action>
  <verify>
    `poetry run knowledge verify --help` shows verify command help
  </verify>
  <done>
    - `knowledge verify` command checks collection health
    - Shows chunk count, document count, dimensions
    - --embeddings flag validates dimension consistency
    - Errors produce exit code 1 with clear messages
  </done>
</task>

<task type="auto">
  <name>Task 2: Add verify command tests</name>
  <files>
    tests/unit/test_cli/test_verify.py
  </files>
  <action>
1. Create tests/unit/test_cli/test_verify.py:

```python
"""Unit tests for verify CLI command."""
from unittest.mock import MagicMock, patch

import pytest
from typer.testing import CliRunner

from knowledge_mcp.cli.main import app

runner = CliRunner()


class TestVerifyCommand:
    """Tests for knowledge verify command."""

    def test_verify_help(self) -> None:
        """Test help message displays."""
        result = runner.invoke(app, ["verify", "--help"])
        assert result.exit_code == 0
        assert "Validate collection health" in result.stdout

    @patch("knowledge_mcp.cli.verify.load_config")
    @patch("knowledge_mcp.cli.verify.create_store")
    def test_verify_success(
        self,
        mock_create_store: MagicMock,
        mock_load_config: MagicMock,
    ) -> None:
        """Test successful verification."""
        # Setup mocks
        mock_config = MagicMock()
        mock_config.embedding_dimensions = 1536
        mock_load_config.return_value = mock_config

        mock_store = MagicMock()
        mock_store.get_collection_stats.return_value = {
            "total_points": 100,
            "unique_documents": 5,
            "vector_dimensions": 1536,
        }
        mock_create_store.return_value = mock_store

        result = runner.invoke(app, ["verify"])

        assert result.exit_code == 0
        assert "100" in result.stdout  # total points
        assert "Verification complete" in result.stdout

    @patch("knowledge_mcp.cli.verify.load_config")
    @patch("knowledge_mcp.cli.verify.create_store")
    def test_verify_embeddings_match(
        self,
        mock_create_store: MagicMock,
        mock_load_config: MagicMock,
    ) -> None:
        """Test embedding dimension verification passes."""
        mock_config = MagicMock()
        mock_config.embedding_dimensions = 1536
        mock_load_config.return_value = mock_config

        mock_store = MagicMock()
        mock_store.get_collection_stats.return_value = {
            "total_points": 100,
            "unique_documents": 5,
            "vector_dimensions": 1536,
        }
        mock_create_store.return_value = mock_store

        result = runner.invoke(app, ["verify", "--embeddings"])

        assert result.exit_code == 0
        assert "OK" in result.stdout
        assert "Dimensions match" in result.stdout

    @patch("knowledge_mcp.cli.verify.load_config")
    @patch("knowledge_mcp.cli.verify.create_store")
    def test_verify_embeddings_mismatch(
        self,
        mock_create_store: MagicMock,
        mock_load_config: MagicMock,
    ) -> None:
        """Test embedding dimension mismatch fails."""
        mock_config = MagicMock()
        mock_config.embedding_dimensions = 1536  # Expected
        mock_load_config.return_value = mock_config

        mock_store = MagicMock()
        mock_store.get_collection_stats.return_value = {
            "total_points": 100,
            "unique_documents": 5,
            "vector_dimensions": 384,  # Actual - mismatch!
        }
        mock_create_store.return_value = mock_store

        result = runner.invoke(app, ["verify", "--embeddings"])

        assert result.exit_code == 1
        assert "MISMATCH" in result.stdout
        assert "1536" in result.stdout  # expected
        assert "384" in result.stdout   # actual

    @patch("knowledge_mcp.cli.verify.load_config")
    @patch("knowledge_mcp.cli.verify.create_store")
    def test_verify_connection_error(
        self,
        mock_create_store: MagicMock,
        mock_load_config: MagicMock,
    ) -> None:
        """Test connection error handling."""
        mock_load_config.return_value = MagicMock()
        mock_create_store.side_effect = Exception("Connection refused")

        result = runner.invoke(app, ["verify"])

        assert result.exit_code == 1
        assert "Error" in result.stdout
        assert "Connection refused" in result.stdout
```

2. Test cases covered:
   - Help text displays correctly
   - Successful verification shows stats
   - Embedding dimensions match (--embeddings flag, exit 0)
   - Embedding dimensions mismatch (--embeddings flag, exit 1)
   - Connection error handling (exit 1)
  </action>
  <verify>
    `poetry run pytest tests/unit/test_cli/test_verify.py -v` passes
  </verify>
  <done>
    - Verify command tests cover help, success, and error cases
    - Tests cover embedding dimension match and mismatch
    - All tests pass
  </done>
</task>

</tasks>

<verification>
1. `poetry run knowledge verify --help` shows command help
2. `poetry run pytest tests/unit/test_cli/test_verify.py -v` passes
3. `poetry run pyright src/knowledge_mcp/cli/verify.py` reports no errors
</verification>

<success_criteria>
- `knowledge verify` command exists and shows help
- Verify displays collection statistics (chunks, documents, dimensions)
- --embeddings flag validates dimension consistency
- Dimension mismatch produces exit code 1
- All tests pass
- pyright passes on new code
</success_criteria>

<output>
After completion, create `.planning/phases/05-extended-features/05-04-SUMMARY.md`
</output>
